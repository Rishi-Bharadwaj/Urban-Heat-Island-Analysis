{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import rasterio as rio\n",
    "from utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tiff_path=r\"C:\\Users\\rishi\\ml_projects\\UHI\\Landsat_0\\Kanpur\\LST\\April.tif\"\n",
    "# with rasterio.open(tiff_path) as src:\n",
    "#     band1=src.read(1)\n",
    "#     print(band1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_points(city_name, shape, N=10000):\n",
    "    rng = np.random.default_rng(seed=hash(city_name) % (2**32)) \n",
    "    rows = rng.integers(0, shape[0], size=N)\n",
    "    cols = rng.integers(0, shape[1], size=N)\n",
    "    return list(zip(rows, cols))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_pixels(tiff_path,tiff_path2,city):\n",
    "    if os.path.exists(tiff_path) and os.path.exists(tiff_path2):\n",
    "        with rasterio.open(tiff_path) as src1, rasterio.open(tiff_path2) as src2:\n",
    "\n",
    "            band10 = src1.read(1).astype(float)  # LST band\n",
    "            cloud = src1.read(3).astype(int)     # Cloud mask band\n",
    "            unc = src1.read(2).astype(float) * 0.01  # Uncertainty band\n",
    "            blue_band=src2.read(1)\n",
    "            green_band=src2.read(2)\n",
    "            red_band=src2.read(3)\n",
    "            nir_band=src2.read(4)\n",
    "            swir1_band=src2.read(5)\n",
    "            swir2_band=src2.read(6)\n",
    "            # Apply cloud mask\n",
    "            mask = cloud_mask(cloud)\n",
    "            red = red_band * 0.0000275 -0.2\n",
    "            nir = nir_band * 0.0000275 -0.2\n",
    "            blue= blue_band * 0.0000275 -0.2\n",
    "            green= green_band * 0.0000275 -0.2\n",
    "            swir1= swir1_band * 0.0000275 -0.2\n",
    "            swir2=swir2_band * 0.0000275 -0.2\n",
    "\n",
    "            ndvi = (nir - red) / (nir + red)\n",
    "            nume= 0.356* blue + 0.130*red +0.373*nir +.085*swir1 +0.072*swir2 -0.0018\n",
    "            albedo=nume/1.016\n",
    "            ndbi= (swir1-nir)/(swir1+nir)\n",
    "           \n",
    "            LST_K = band10 * 0.00341802 + 149\n",
    "            LST_C = LST_K - 273.15\n",
    "\n",
    "            # Apply masking\n",
    "            lst2 = np.copy(LST_C)\n",
    "            lst2[(mask == 1)] = np.nan  \n",
    "            nan_count=np.isnan(lst2).sum()\n",
    "            # if nan_count>= 0.4* lst2.shape[0]*lst2.shape[1]:\n",
    "            #     raise ValueError(\"Too many missing points\")\n",
    "            \n",
    "            shape=np.shape(lst2)\n",
    "            points=get_sample_points(city,shape)\n",
    "            data=[]\n",
    "            for point in points:\n",
    "                row={}\n",
    "                if not np.isnan(lst2[point[0]][point[1]]):\n",
    "                    row[\"LST\"]=lst2[point[0]][point[1]]\n",
    "                    row[\"NDVI\"]=ndvi[point[0]][point[1]]\n",
    "                    row[\"NDBI\"]=ndbi[point[0]][point[1]]\n",
    "                    row[\"Albedo\"]=albedo[point[0]][point[1]]\n",
    "                else:\n",
    "                    row[\"LST\"]=np.nan\n",
    "                    row[\"NDVI\"]=np.nan\n",
    "                    row[\"NDBI\"]=np.nan\n",
    "                    row[\"Albedo\"]=np.nan\n",
    "                data.append(row)\n",
    "            df=pd.DataFrame(data)\n",
    "            return df\n",
    "        \n",
    "    else:\n",
    "        raise FileNotFoundError(\"One or both TIFF paths do not exist.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n",
      "2024\n"
     ]
    }
   ],
   "source": [
    "cities=[\"Delhi\",\"Hyderabad\", \"Mumbai\", \"Bangalore\",\"Kolkata\",\"Chennai\",\"Pune\",\\\n",
    "        \"Kanpur\",\"Surat\",\"Ahmedabad\"]\n",
    "months = {\n",
    "        1: (\"January\", 31),\n",
    "        2: (\"February\", 28),\n",
    "        3: (\"March\", 31),\n",
    "        4: (\"April\", 30),\n",
    "        5: (\"May\", 31),\n",
    "        6: (\"June\", 30),\n",
    "        7: (\"July\", 31),\n",
    "        8: (\"August\", 31),\n",
    "        9: (\"September\", 30),\n",
    "        10: (\"October\", 31),\n",
    "        11: (\"November\", 30),\n",
    "        12: (\"December\", 31)\n",
    "    }\n",
    "data=[]\n",
    "month_count=0\n",
    "for year in range(2000,2025):\n",
    "    for month in months:\n",
    "        month_count+=1\n",
    "        for city in cities:\n",
    "            row = {\"Year\": year, \"Month\": month, \"Aggregate_Month\":month_count, \"City\": city}\n",
    "            lst_t=fr\"/home/f20222001/test-venv/UHI/Landsat_{year-2000}/{city}/LST/{months[month][0]}.tif\"\n",
    "            ndvi_t=fr\"/home/f20222001/test-venv/UHI/Landsat_{year-2000}/{city}/NDVI/{months[month][0]}.tif\"\n",
    "            try:\n",
    "               row[\"Pointwise_Data\"]=get_features_pixels(lst_t,ndvi_t,city)\n",
    "            except Exception as e:\n",
    "                row[\"Pointwise_Data\"]=np.nan\n",
    "            data.append(row)\n",
    "    print(year)\n",
    "df=pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Aggregate_Month</th>\n",
       "      <th>City</th>\n",
       "      <th>Pointwise_Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>LST      NDVI      NDBI    Albedo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>LST      NDVI      NDBI    Albedo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Surat</td>\n",
       "      <td>LST      NDVI      NDBI    Albedo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>LST      NDVI      NDBI    Albedo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>LST      NDVI      NDBI    Albed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1798</th>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "      <td>300</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>LST      NDVI      NDBI    Albedo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1799</th>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "      <td>300</td>\n",
       "      <td>Pune</td>\n",
       "      <td>LST      NDVI      NDBI    Albedo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1800</th>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "      <td>300</td>\n",
       "      <td>Kanpur</td>\n",
       "      <td>LST      NDVI      NDBI    Albedo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1801</th>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "      <td>300</td>\n",
       "      <td>Surat</td>\n",
       "      <td>LST      NDVI      NDBI    Albedo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1802</th>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "      <td>300</td>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>LST      NDVI      NDBI    Albedo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1803 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Year  Month  Aggregate_Month       City  \\\n",
       "0     2000      1                1  Hyderabad   \n",
       "1     2000      1                1    Chennai   \n",
       "2     2000      1                1      Surat   \n",
       "3     2000      1                1  Ahmedabad   \n",
       "4     2000      2                2      Delhi   \n",
       "...    ...    ...              ...        ...   \n",
       "1798  2024     12              300    Chennai   \n",
       "1799  2024     12              300       Pune   \n",
       "1800  2024     12              300     Kanpur   \n",
       "1801  2024     12              300      Surat   \n",
       "1802  2024     12              300  Ahmedabad   \n",
       "\n",
       "                                         Pointwise_Data  \n",
       "0                  LST      NDVI      NDBI    Albedo...  \n",
       "1                  LST      NDVI      NDBI    Albedo...  \n",
       "2                  LST      NDVI      NDBI    Albedo...  \n",
       "3                  LST      NDVI      NDBI    Albedo...  \n",
       "4                   LST      NDVI      NDBI    Albed...  \n",
       "...                                                 ...  \n",
       "1798               LST      NDVI      NDBI    Albedo...  \n",
       "1799               LST      NDVI      NDBI    Albedo...  \n",
       "1800               LST      NDVI      NDBI    Albedo...  \n",
       "1801               LST      NDVI      NDBI    Albedo...  \n",
       "1802               LST      NDVI      NDBI    Albedo...  \n",
       "\n",
       "[1803 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(subset=[\"Pointwise_Data\"], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(\"pixelated_db_10_fk.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LST</th>\n",
       "      <th>NDVI</th>\n",
       "      <th>NDBI</th>\n",
       "      <th>Albedo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33.212223</td>\n",
       "      <td>0.314720</td>\n",
       "      <td>0.187720</td>\n",
       "      <td>0.138333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32.784970</td>\n",
       "      <td>0.203027</td>\n",
       "      <td>0.116432</td>\n",
       "      <td>0.188628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37.847058</td>\n",
       "      <td>0.222606</td>\n",
       "      <td>0.161355</td>\n",
       "      <td>0.181382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31.311804</td>\n",
       "      <td>0.294090</td>\n",
       "      <td>0.015158</td>\n",
       "      <td>0.168077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.313284</td>\n",
       "      <td>0.270867</td>\n",
       "      <td>0.169398</td>\n",
       "      <td>0.200220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>32.952453</td>\n",
       "      <td>0.291216</td>\n",
       "      <td>0.129683</td>\n",
       "      <td>0.172204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>35.939803</td>\n",
       "      <td>0.111702</td>\n",
       "      <td>0.092735</td>\n",
       "      <td>0.145024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>36.585809</td>\n",
       "      <td>0.175635</td>\n",
       "      <td>0.132946</td>\n",
       "      <td>0.205878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>36.445670</td>\n",
       "      <td>0.290567</td>\n",
       "      <td>0.086115</td>\n",
       "      <td>0.141747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>34.282063</td>\n",
       "      <td>0.210647</td>\n",
       "      <td>0.147797</td>\n",
       "      <td>0.192521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             LST      NDVI      NDBI    Albedo\n",
       "0      33.212223  0.314720  0.187720  0.138333\n",
       "1      32.784970  0.203027  0.116432  0.188628\n",
       "2      37.847058  0.222606  0.161355  0.181382\n",
       "3      31.311804  0.294090  0.015158  0.168077\n",
       "4      32.313284  0.270867  0.169398  0.200220\n",
       "...          ...       ...       ...       ...\n",
       "39995  32.952453  0.291216  0.129683  0.172204\n",
       "39996  35.939803  0.111702  0.092735  0.145024\n",
       "39997  36.585809  0.175635  0.132946  0.205878\n",
       "39998  36.445670  0.290567  0.086115  0.141747\n",
       "39999  34.282063  0.210647  0.147797  0.192521\n",
       "\n",
       "[40000 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Pointwise_Data\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/f20222001/test-venv/UHI/New Notebooks/pixelated_db_10k.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m newdf=\u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_pickle\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/home/f20222001/test-venv/UHI/New Notebooks/pixelated_db_10k.pkl\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m newdf[\u001b[33m'\u001b[39m\u001b[33mPointwise_Data\u001b[39m\u001b[33m'\u001b[39m][\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/test-venv/venv/lib/python3.12/site-packages/pandas/io/pickle.py:185\u001b[39m, in \u001b[36mread_pickle\u001b[39m\u001b[34m(filepath_or_buffer, compression, storage_options)\u001b[39m\n\u001b[32m    123\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    124\u001b[39m \u001b[33;03mLoad pickled pandas object (or any object) from file.\u001b[39;00m\n\u001b[32m    125\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    182\u001b[39m \u001b[33;03m4    4    9\u001b[39;00m\n\u001b[32m    183\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    184\u001b[39m excs_to_catch = (\u001b[38;5;167;01mAttributeError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m, \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    190\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[32m    192\u001b[39m     \u001b[38;5;66;03m# 1) try standard library Pickle\u001b[39;00m\n\u001b[32m    193\u001b[39m     \u001b[38;5;66;03m# 2) try pickle_compat (older pandas version) to handle subclass changes\u001b[39;00m\n\u001b[32m    194\u001b[39m     \u001b[38;5;66;03m# 3) try pickle_compat with latin-1 encoding upon a UnicodeDecodeError\u001b[39;00m\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    197\u001b[39m         \u001b[38;5;66;03m# TypeError for Cython complaints about object.__new__ vs Tick.__new__\u001b[39;00m\n\u001b[32m    198\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/test-venv/venv/lib/python3.12/site-packages/pandas/io/common.py:882\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    873\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(\n\u001b[32m    874\u001b[39m             handle,\n\u001b[32m    875\u001b[39m             ioargs.mode,\n\u001b[32m   (...)\u001b[39m\u001b[32m    878\u001b[39m             newline=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    879\u001b[39m         )\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m882\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    883\u001b[39m     handles.append(handle)\n\u001b[32m    885\u001b[39m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/home/f20222001/test-venv/UHI/New Notebooks/pixelated_db_10k.pkl'"
     ]
    }
   ],
   "source": [
    "newdf=pd.read_pickle(r\"/home/f20222001/test-venv/UHI/New Notebooks/pixelated_db_10k.pkl\")\n",
    "newdf['Pointwise_Data'][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
